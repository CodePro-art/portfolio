---
slug: machine-learning-vs-deep-learning
title: Learn the Difference Between Machine Learning and Deep Learning
description: The Ultimate Comparison of Machine Learning vs Deep Learning
banner: ai-driven-disinformation.mp4
bannerPlaceholder: ai-driven-disinformation-placeholder.jpg
bannerAlt: A ThreeJS scene, featuring a cube that reacts to devices' accessibility settings.
tags: ['deepfake', 'artificial intelligence', 'futurology', 'AI']
date: 2024-09-02
readTime: '00:15:00:00'
---

## How to avoid being fooled by AI-generated misinformation  

Advances in generative AI mean fake images, videos, audio and bots are now everywhere. But studies have revealed the best ways to tell if something is real

![OpenAI Sora– The most realistic AI-generated video to date.](realistic-ai-gen.jpg)

Did you notice that the image above was created by artificial intelligence? It can be difficult to spot AI-generated images, video, audio and text at a time when technological advances are making them increasingly indistinguishable from much human-created content, leaving us open to manipulation by disinformation. But by knowing the current state of the AI technologies used to create misinformation, and the range of telltale signs that what you are looking at might be fake, you can help protect yourself from being taken in.

World leaders are concerned. According to a [report by the World Economic Forum](https://www.weforum.org/publications/global-risks-report-2024/in-full/), misinformation and disinformation may “radically disrupt electoral processes in several economies over the next two years”, while easier access to AI tools “have already enabled an explosion in falsified information and so-called ‘synthetic’ content, from sophisticated voice cloning to counterfeit websites”.

The terms misinformation and disinformation both refer to false or inaccurate information, but disinformation is that which is deliberately intended to deceive or mislead.

“The issue with AI-powered disinformation is the scale, speed and ease with which campaigns can be launched,” says [Hany Farid](https://www.ischool.berkeley.edu/people/hany-farid) at the University of California, Berkeley. “These attacks will no longer take state-sponsored actors or well-financed organizations – a single individual with access to some modest computing power can create massive amounts of fake content.”

He says that generative AI is “polluting the entire information ecosystem, casting everything we read, see and hear into doubt”. He says his research suggests that, in many cases, AI-generated images and audio are “nearly indistinguishable from reality”.

However, research by Farid and others reveals that there are strategies you can follow to reduce your risk of falling for social media misinformation or disinformation created by AI.

## How to spot fake AI images

Remember seeing a photo of Pope Francis wearing a puffer jacket? Such fake AI images have become more common as new tools based on diffusion models have allowed anyone to start churning out images from simple text prompts. One [study](https://arxiv.org/abs/2405.11697) by Nicholas Dufour at Google and his colleagues found a rapid increase in the proportion of AI-generated images in fact-checked misinformation claims from early 2023 onwards.

![Pope Francis wearing a puffer jacket AI-generated Image](ai-pope.avif)
“Nowadays, media literacy requires AI literacy,” says [Negar Kamali](https://scholar.google.com/citations?user=BtbeIckAAAAJ&hl=en) at Northwestern University in Illinois. In a 2024 [study](https://arxiv.org/abs/2406.08651), she and her colleagues identified five different categories of errors in AI-generated images (outlined below) and provided guidance on how people can spot these for themselves. The good news is that their research suggests people are currently about 70 per cent accurate at detecting fake AI images of people. You can use their [online image test](https://detectfakes.kellogg.northwestern.edu/) to assess your own sleuthing skills.

__5 common types of errors in AI-generated images:__

- __Sociocultural implausibilities:__ Is the scene depicting rare, unusual or surprising behavior for certain cultures or historical figures?
- __Anatomical implausibilities:__ Take a close look: are body parts like hands unusually shaped or sized? Do the eyes or mouths look strange? Have any body parts merged?
- __Stylistic artifacts:__ Does the image look unnatural, almost too perfect or stylistic? Does the background look odd or like it is missing something? Is the lighting strange or variable?
- __Functional implausibilities:__ Do any objects look bizarre or like they might not be real or work? For example, are buttons or belt buckles in weird places?
- __Violations of physics:__ Are shadows pointing in different directions? Are mirror reflections consistent with the world depicted within the image?

![Strange objects and behavior can be clues that an image was created by AI](weird-ai.avif)

## How to spot fake AI video  

AI technology known as generative adversarial networks has allowed tech-savvy individuals to create [video deepfakes](https://www.newscientist.com/article/2418188-deepfakes-are-out-of-control-is-it-too-late-to-stop-them/) since 2014 – digitally manipulating existing videos of people to swap in different faces, create new facial expressions and insert new spoken audio aligned with matching lip-syncing. This has enabled a growing array of scammers, state-backed hackers and internet users to produce video deepfakes where celebrities such as Taylor Swift and ordinary people alike may find themselves unwillingly featured in non-consensual deepfake pornography, scams and political misinformation or disinformation.

The techniques for spotting AI fake images (see above) can be applied to suspect videos too. Additionally, researchers at the Massachusetts Institute of Technology and Northwestern University in Illinois have compiled [some tips](https://www.media.mit.edu/projects/detect-fakes/overview/) for how to spot such deepfakes, but they have acknowledged that there is no fool-proof method that always works.

__6 tips for spotting AI-generated video:__

- __Mouth and lip movements:__ Are there moments when the video and audio aren’t completely synced?
- __Anatomical glitches:__ Does the face or body look weird or move unnaturally?
- __Face:__ Look for inconsistencies in face smoothness or wrinkles around the forehead and cheeks, along with facial moles.
- __Lighting:__ Is the lighting inconsistent? Do shadows behave as you would expect? Pay particular attention to a person’s eyes, eyebrows and glasses.
- __Hair:__ Does facial hair look weird or move in strange ways?
- __Blinking:__ Too much or too little blinking could be a sign of a deepfake.

A newer category of video deepfakes is based on diffusion models – the same AI technology behind many image generators – that can create completely AI-generated video clips based on text prompts. Companies are already testing and releasing commercial versions of AI video generators that could make it easy for anyone to do this without needing special technical knowledge. So far, the resulting videos tend to feature distorted faces or bizarre body movements.

“These AI-generated videos are probably easier for people to detect than images, because there is a lot of movement and there is a lot more opportunity for AI-generated artifacts and impossibilities,” says Kamali.

<iframe 
  className="article-iframe"
  width="800" 
  height="500"
  src="https://www.youtube.com/embed/7akzhpx0EIU" 
  title="YouTube video player" 
  frameBorder="0" 
  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
  allowFullScreen>
</iframe>

## How to identify AI bots

Social media accounts controlled by computer bots have become common on many social media and messaging platforms. A growing number of these bots have also been taking advantage of generative AI technologies such as large language models since 2022. These make it both easy and cheap to churn out AI-written content through thousands of bots that is grammatically correct and convincingly customised to different situations.

It has become much easier “to customize these large language models for specific audiences with specific messages”, says [Paul Brenner](https://crc.nd.edu/about/people/paul-brenner/) at the University of Notre Dame in Indiana.

Brenner and his colleagues have found in their research that volunteers could only distinguish AI-powered bots from humans [about 42 per cent of the time](https://arxiv.org/abs/2402.07940) – despite the participants being told they were potentially interacting with bots. You can test your own bot detection skills [here](https://nd.qualtrics.com/jfe/form/SV_dgy2Ymsq74ZkNOm).

Some strategies can help identify less sophisticated AI bots, says Brenner.

__5 ways to determine whether a social media account is an AI bot:__

- __Emojis and hashtags:__ Excessive use of these can be a sign.
- __Uncommon phrasing, word choices or analogies:__ Unusual wording could indicate an AI bot.
- __Repetition and structure:__ Bots may use repeated wording that follows similar or rigid forms and they may overuse certain slang terms.
- __Ask questions:__ These can reveal a bot’s lack of knowledge about a topic – particularly when it comes to local places and situations.
- __Assume the worst:__ If a social media account isn’t a personal contact and their identity hasn’t been clearly validated or verified, it could well be an AI bot.

## How to detect audio cloning and speech deepfakes

Voice cloning AI tools have made it easy to generate new spoken audio that can mimic practically anyone. This has led to the rise of audio deepfake scams that clone the voices of family members, company executives and political leaders such as US President Joe Biden. These can be much more difficult to identify compared with AI-generated videos or images.

“Voice cloning is particularly challenging to distinguish between real and fake because there aren’t visual components to support our brains in making that decision,” says [Rachel Tobac](https://www.linkedin.com/in/racheltobac/), co-founder of SocialProof Security, a white-hat hacking organisation.

Detecting such AI audio deepfakes can be especially tricky when they are used in video and phone calls. But there are some common-sense steps you can follow to distinguish authentic humans from AI-generated voices.

<iframe 
  className="article-iframe"
  width="800" 
  height="500"
  src="https://www.youtube.com/embed/3wVpVH0Wa6E"
  title="YouTube video player" 
  frameBorder="0" 
  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
  allowFullScreen>
</iframe>

__4 steps for recognizing if audio has been cloned or faked using AI:__

- __Public figures:__ If the audio clip is of an elected official or celebrity, check if what they are saying is consistent with what has already been publicly reported or shared about their views and behavior.
- __Look for inconsistencies:__ Compare the audio clip with previously authenticated video or audio clips that feature the same person’s voice. Are there any inconsistencies in the sound of their voice or their speech mannerisms?
- __Awkward silences:__ If you are listening to a phone call or voicemail and the speaker is taking unusually long pauses while speaking, they may be using AI-powered voice cloning technology.
- __Weird and wordy:__ Any robotic speech patterns or an unusually verbose manner of speaking could indicate that someone is using a combination of voice cloning to mimic a person’s voice and a large language model to generate the exact wording.

## The technology will only get better  

As it stands, there are no consistent rules that can always distinguish AI-generated content from authentic human content. AI models capable of generating text, images, video and audio will almost certainly continue to improve and they can often quickly produce authentic-seeming content without any obvious artefacts or mistakes. “Be politely paranoid and realise that AI has been manipulating and fabricating pictures, videos and audio fast – we’re talking completed in 30 seconds or less,” says Tobac. “This makes it easy for malicious individuals who are looking to trick folks to turn around AI-generated disinformation quickly, hitting social media within minutes of breaking news.”

While it is important to hone your eye for AI-generated false information and learn to ask more questions of what you read, see and hear, ultimately this won’t be enough to stop harm and the responsibility to detect fakes can’t fall fully on individuals. Farid is among researchers who say that government regulators must hold to account the largest tech companies – along with start-ups backed by prominent Silicon Valley investors – that have developed many of the tools that are flooding the internet with fake AI-generated content. “Technology is not neutral,” says Farid. “This line that the technology sector has sold us that somehow they don’t have to absorb liability where every other industry does, I simply reject it.”

## AI glossary

__Diffusion models:__ AI models that learn by first adding random noise to data – such as blurring an image – and then reversing the process to recover the original data.

__Generative adversarial networks:__ A machine learning method based on two neural networks that compete by modifying original data and then try to predict whether the generated data is authentic or real.

__Generative AI:__ A broad class of AI models that can produce text, images, audio and video after being trained on similar forms of such content.

__Large language models:__ A subset of generative AI models that can produce different forms of written content in response to text prompts and sometimes translate between various languages.

__Voice cloning:__ The method of using AI models to create a digital copy of a person’s voice and then potentially generating new speech samples in that voice.
